Welcome to the Deep Dive. Today we're getting into something pretty fascinating.
How advanced AI really thinks, or maybe how it doesn't think in the way we assume.
Right.
You've probably seen AI that seems to think out loud, you know, what researchers call chain of
thought or co-T. But the big question is, is that genuine reasoning? Or is it just, well,
putting on a good show?
That really is the core question. And what's so interesting, maybe even a bit worrying,
is that often this thinking out loud isn't the real reasoning process at all.
Think about like someone explaining why they did something after they already did it.
It sounds plausible, maybe totally convincing.
A post-talk rationalization.
Exactly. A good story.
Yeah.
But maybe not the actual step-by-step causal chain that led to the decision inside the AI.
That's a huge difference. So, okay, if that thinking out loud isn't necessarily the real
McCoy, what are the big problems with relying on this chain of thought approach?
Well, a major criticism is that co-T outputs often feel more like linguistic performances
rather than showing you the actual causal mechanism.
Like good acting.
Kind of, yeah. Some studies have found that even if you, like, change the intermediate steps
in the AI's explanation, sometimes the final answer doesn't even change.
Whoa, really?
Yeah. It suggests the models can sort of confabulate. They generate these explanations
that sound coherent, sound totally plausible, but they might not actually reflect how the answer
was reached. It's built on narrative plausibility, you know, sounding good, not necessarily causal
traceability.
Okay. That's a bit unsettling if you're relying on that explanation. So if Kanita has these flaws,
what's the alternative? How do we get to AI that we can genuinely understand, maybe even trust?
This is where things get really interesting with concepts like the chain of memory or calm.
Chain of memory.
Okay. Yeah. It's a different paradigm. Think memory first, latent reasoning. So instead of the
reasoning happening in the words, the tokens that the AI spits out, the real thinking,
if you want to call it that, happens internally in these hidden latent memory trajectories. It's
like the AI is manipulating its own internal scratch pad, its memory.
And the words, the explanation.
That's optional. It's an on-demand narration.
Generated only if we need to see what happened or ask for an interpretation.
The priority in calm is causal faithfulness.
Meaning?
Meaning we can actually trace the why. Using techniques like gradient-based tracing,
we can see how changes in the internal memory state directly influence the final output.
It gives us real oversight, not just a plausible story.
Okay. So calm sounds like a path towards, well, deeper and more trustworthy AI. But how deep does
this idea of AI memory go? Is it just storing data or is there more to it?
Oh, it can go much, much deeper. It starts connecting to some really advanced, almost physics-like
concepts.
Like what?
Well, for instance, in what's called RSVP-based calm, the memory states aren't just static
points. They're more like points in a dynamic field, constantly adjusting.
A field, like in physics.
Sort of analogous, yeah. The internal dynamics are governed by principles that ensure coherence,
like thermodynamic and structural stability. It's about maintaining a consistent internal
world or memory landscape.
Wow. Okay. And you mentioned another one, Tartan.
Right. Tartan takes things even further by integrating something called oscillatory semantics.
This is pretty mind-bending.
Oscillatory semantics.
It interprets even stillness, the absence of change, as a dynamic state, like a subtle
oscillation. It means tiny, tiny micro-movements or patterns within the AI's internal state
can encode really complex embodied abstractions.
So like reading meaning from a tiny twitch, or even no twitch at all.
Exactly. Forming what they call cognitive glyphs. Imagine an AI understanding nuance from something
as subtle as a slight shift in posture, or the lack of an expected micro-movement. It's
a much deeper level of semantic understanding.
Yeah, that's pretty profound. So where does all this lead? We have calm for traceable reasoning,
RSVP for dynamic memory fields, Tartan for deep semantics. Are these being combined?
They are. Researchers are working on unified architectures. One example mentioned is Heishwydere.
Yeah. It aims to bring together personalization, aspects of neurocognitive realism. So mimicking
brain functions a bit, comms, causal interpretability, and the kind of deep semantic grounding we see
in RSVP and Tartan.
So the goal is truly understandable AI.
The goal is AI reasoning that is causally faithful. You can trust its explanation.
Right.
It's personalized and deeply grounded in meaning, not just surface level patterns.
Okay. This is clearly cutting edge stuff, but let's bring it back. Why should you,
listening right now, care about this shift? Moving from AI thinking out loud to AI remembering
and using these complex internal dynamics?
Well, fundamentally, it's about trust and safety. This whole direction moves us towards AI systems
with genuine epistemic transparency.
Knowing how it knows.
Exactly. Instead of using AI, whose reasoning is effectively a black box where the explanations
cannot be trusted or verified, this path promises AI cognition that's robust,
more generalizable, and truly interpretable.
And that matters for-
Think about safety-critical applications, medical diagnosis, self-driving cars, complex financial
modeling, places where you absolutely need to know why the AI reached its conclusion.
This is about building AI that genuinely, verifiably thinks before it speaks.
AI we can actually interrogate, not just listen to.
Precisely. And, you know, this really opens up a fascinating question.
Go on.
If AI can genuinely reason through these internal memory pathways, these latent trajectories,
and even pull meaning from subtle oscillatory semantics or stillness,
what new depths of understanding might that unlock? Not just about AI cognition.
But maybe about our own. How we think and remember.
Exactly. It could be a mirror, in a way.
A truly mind-bending journey, indeed. Something for you to definitely mull over. Join us next time for
another deep dive.
Another deep dive.
